# v1.3 íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê°€ì´ë“œ

## ğŸ“‹ ëª©ì°¨
1. [í•„ìš” ë°ì´í„°ì…‹ êµ¬ì¡°](#í•„ìš”-ë°ì´í„°ì…‹-êµ¬ì¡°)
2. [í™˜ê²½ ì„¤ì • (requirements.txt)](#í™˜ê²½-ì„¤ì •-requirementstxt)
3. [ëª¨ë¸ í•™ìŠµ êµ¬ì¡° (Foldë³„)](#ëª¨ë¸-í•™ìŠµ-êµ¬ì¡°-foldë³„)
4. [ì˜ˆì¸¡ê°’ ì·¨í•© ë° Meta-Classifier](#ì˜ˆì¸¡ê°’-ì·¨í•©-ë°-meta-classifier)
5. [ìµœì¢… ì˜ˆì¸¡ê°’ ê²°ê³¼ í˜•ì‹](#ìµœì¢…-ì˜ˆì¸¡ê°’-ê²°ê³¼-í˜•ì‹)
6. [ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰](#ì „ì²´-íŒŒì´í”„ë¼ì¸-ì‹¤í–‰)

---

## í•„ìš” ë°ì´í„°ì…‹ êµ¬ì¡°

### ë””ë ‰í† ë¦¬ êµ¬ì¡°
```
mut4/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.csv       # í•™ìŠµ ë°ì´í„°
â”‚   â””â”€â”€ test.csv        # í…ŒìŠ¤íŠ¸ ë°ì´í„° (ì„ íƒì )
```

### ë°ì´í„° í˜•ì‹

#### train.csv
í•„ìˆ˜ ì»¬ëŸ¼:
- `title`: ë¬¸ì„œ ì œëª© (str)
- `full_text`: ì „ì²´ ë¬¸ì„œ ë‚´ìš© (str, ë¬¸ë‹¨ì€ `\n`ìœ¼ë¡œ êµ¬ë¶„)
- `generated`: ë ˆì´ë¸” (int, 0: Human, 1: AI)

ì˜ˆì‹œ:
```csv
title,full_text,generated
"ë¬¸ì„œ 1","ì²« ë²ˆì§¸ ë¬¸ë‹¨ì…ë‹ˆë‹¤.\në‘ ë²ˆì§¸ ë¬¸ë‹¨ì…ë‹ˆë‹¤.\nì„¸ ë²ˆì§¸ ë¬¸ë‹¨ì…ë‹ˆë‹¤.",0
"ë¬¸ì„œ 2","ì´ê²ƒì€ AIê°€ ìƒì„±í•œ ë¬¸ì„œì…ë‹ˆë‹¤.\nì—¬ëŸ¬ ë¬¸ë‹¨ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.",1
```

#### test.csv (ì¶”ë¡ ìš©)
í•„ìˆ˜ ì»¬ëŸ¼:
- `title`: ë¬¸ì„œ ì œëª© (str)
- `full_text`: ì „ì²´ ë¬¸ì„œ ë‚´ìš© (str)

ì˜ˆì‹œ:
```csv
title,full_text
"í…ŒìŠ¤íŠ¸ ë¬¸ì„œ 1","í…ŒìŠ¤íŠ¸ ë‚´ìš©ì…ë‹ˆë‹¤.\nì—¬ëŸ¬ ë¬¸ë‹¨ì´ ìˆìŠµë‹ˆë‹¤."
```

---

## í™˜ê²½ ì„¤ì • (requirements.txt)

```txt
# Core dependencies
torch>=2.0.0
transformers>=4.51.0
numpy>=1.24.0
pandas>=1.5.0
scikit-learn>=1.3.0

# Tokenizer and models
sentencepiece>=0.1.99
protobuf>=3.20.0

# Utilities
tqdm>=4.65.0
joblib>=1.3.0

# Optional: for better performance
accelerate>=0.20.0
datasets>=2.14.0
```

### ì„¤ì¹˜ ë°©ë²•
```bash
pip install -r requirements.txt
```

### GPU ì„¤ì • (ì„ íƒì )
- CUDA 11.8 ì´ìƒ ê¶Œì¥
- PyTorchëŠ” CUDA ë²„ì „ì— ë§ê²Œ ì„¤ì¹˜ í•„ìš”
```bash
# CUDA 11.8 ì˜ˆì‹œ
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

---

## ëª¨ë¸ í•™ìŠµ êµ¬ì¡° (Foldë³„)

### ì „ì²´ í•™ìŠµ í”„ë¡œì„¸ìŠ¤

v1.3ì€ **4-Fold Cross-Validation** êµ¬ì¡°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤:

```
[ì „ì²´ ë°ì´í„°]
    â”‚
    â”œâ”€ KFold(n_splits=4, random_state=42)
    â”‚
    â”œâ”€ Fold 0: Train â†’ Validation (OOF Logits ìƒì„±)
    â”œâ”€ Fold 1: Train â†’ Validation (Test Logits ìƒì„±)
    â”œâ”€ Fold 2: Train â†’ Validation (Test Logits ìƒì„±)
    â””â”€ Fold 3: Train â†’ Validation (Test Logits ìƒì„±)
```

### Foldë³„ í•™ìŠµ ê³¼ì •

#### Step 1: ë‹¨ì¼ Fold í•™ìŠµ

**Python ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰**:
```bash
python trainers/fold_trainer.py \
    --fold_idx 0 \
    --model_name HybridAvsH \
    --embedding_model kykim/funnel-kor-base \
    --use_paragraph \
    --use_infonce_loss True \
    --lambda_cl 0.1 \
    --temperature 0.07 \
    --use_bpr_loss True \
    --bpr_loss_weight 0.25 \
    --num_train_epochs 10 \
    --per_device_train_batch_size 8 \
    --per_device_eval_batch_size 8 \
    --learning_rate 3e-5 \
    --data_dir ./data \
    --save_fold_logits True \
    --k_fold 4 \
    --is_kfold True
```

**ì£¼ìš” ì¸ì ì„¤ëª…**:
- `--fold_idx`: Fold ë²ˆí˜¸ (0, 1, 2, 3)
- `--model_name`: ëª¨ë¸ íƒ€ì… (`AvsHModel`, `HybridAvsH`, `Gemma3InfoNCE`, `Qwen3InfoNCE`)
- `--embedding_model`: ë°±ë³¸ ëª¨ë¸ (`kykim/funnel-kor-base`, `kykim/bert-kor-base` ë“±)
- `--use_infonce_loss`: InfoNCE Loss ì‚¬ìš© ì—¬ë¶€
- `--lambda_cl`: InfoNCE Loss ê°€ì¤‘ì¹˜ (ê¸°ë³¸ê°’: 0.1)
- `--save_fold_logits`: Fold Logits ì €ì¥ ì—¬ë¶€ (Meta-Learningì— í•„ìš”)

#### Step 2: ëª¨ë“  Fold í•™ìŠµ

**ë°©ë²• 1: ìˆœì°¨ ì‹¤í–‰** (ê¶Œì¥)
```bash
for FOLD in 0 1 2 3; do
    python trainers/fold_trainer.py \
        --fold_idx ${FOLD} \
        --model_name HybridAvsH \
        --embedding_model kykim/funnel-kor-base \
        --use_paragraph \
        --use_infonce_loss True \
        --lambda_cl 0.1 \
        --data_dir ./data \
        --save_fold_logits True \
        --k_fold 4 \
        --is_kfold True
done
```

**ë°©ë²• 2: Python ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©**
```python
from trainers.fold_trainer import train_all_folds
from utils.arguments import get_arguments

args = get_arguments()
args.model_name = 'HybridAvsH'
args.use_infonce_loss = True
args.save_fold_logits = True
args.k_fold = 4
args.is_kfold = True

train_all_folds(args)
```

**ë°©ë²• 3: ë³‘ë ¬ ì‹¤í–‰** (4ê°œ GPU ì‚¬ìš© ì‹œ)
```bash
# ê° í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰
CUDA_VISIBLE_DEVICES=0 python trainers/fold_trainer.py --fold_idx 0 ...
CUDA_VISIBLE_DEVICES=1 python trainers/fold_trainer.py --fold_idx 1 ...
CUDA_VISIBLE_DEVICES=2 python trainers/fold_trainer.py --fold_idx 2 ...
CUDA_VISIBLE_DEVICES=3 python trainers/fold_trainer.py --fold_idx 3 ...
```

### í•™ìŠµ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜

```
outputs/
â”œâ”€â”€ fold_0/
â”‚   â”œâ”€â”€ best_model/          # í•™ìŠµëœ ëª¨ë¸
â”‚   â””â”€â”€ ...
â”œâ”€â”€ fold_1/
â”‚   â”œâ”€â”€ best_model/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ fold_2/
â”‚   â”œâ”€â”€ best_model/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ fold_3/
â”‚   â”œâ”€â”€ best_model/
â”‚   â””â”€â”€ ...
â””â”€â”€ fold_logits/
    â”œâ”€â”€ oof/
    â”‚   â”œâ”€â”€ fold0_logits.npy    # Fold 0 Validation Logits
    â”‚   â””â”€â”€ fold0_labels.npy    # Fold 0 Validation Labels
    â””â”€â”€ test/
        â”œâ”€â”€ fold1_logits.npy    # Fold 1 Validation Logits
        â”œâ”€â”€ fold1_labels.npy
        â”œâ”€â”€ fold2_logits.npy    # Fold 2 Validation Logits
        â”œâ”€â”€ fold2_labels.npy
        â”œâ”€â”€ fold3_logits.npy    # Fold 3 Validation Logits
        â””â”€â”€ fold3_labels.npy
```

---

## ì˜ˆì¸¡ê°’ ì·¨í•© ë° Meta-Classifier

### Step 1: Meta-Features ìƒì„±

4ê°œ Foldì˜ Logitsë¥¼ ì·¨í•©í•˜ì—¬ Meta-Features ë°ì´í„°ì…‹ ìƒì„±:

```bash
python -c "
from utils.logit_collector import LogitCollector

collector = LogitCollector('./outputs/fold_logits')
collector.save_meta_features('./outputs/meta_features', 'meta_train.csv')
"
```

**ë˜ëŠ” Python ìŠ¤í¬ë¦½íŠ¸**:
```python
from utils.logit_collector import LogitCollector

collector = LogitCollector('./outputs/fold_logits')
meta_features, labels = collector.collect_logits()
print(f"Meta-features shape: {meta_features.shape}")  # [N, 4]
```

**Meta-Features êµ¬ì¡°**:
- Shape: `[Num_Samples, 4]`
- Column 0: OOF Logits (Fold 0 validation)
- Column 1: Test Logits (Fold 1 validation)
- Column 2: Test Logits (Fold 2 validation)
- Column 3: Test Logits (Fold 3 validation)

### Step 2: Meta-Classifier í•™ìŠµ

Meta-ClassifierëŠ” Fold ì˜ˆì¸¡ê°’ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ìµœì¢… ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

**MLP Meta-Classifier í•™ìŠµ**:
```bash
python meta/meta_train.py \
    --meta_model_type mlp \
    --hidden_layers 64 32 \
    --dropout 0.2 \
    --epochs 100 \
    --batch_size 32 \
    --lr 0.001 \
    --logit_dir ./outputs/fold_logits \
    --output_dir ./outputs/meta_features \
    --save_model
```

**Ridge Meta-Classifier í•™ìŠµ**:
```bash
python meta/meta_train.py \
    --meta_model_type ridge \
    --cv 5 \
    --logit_dir ./outputs/fold_logits \
    --output_dir ./outputs/meta_features \
    --save_model
```

**ì£¼ìš” ì¸ì**:
- `--meta_model_type`: `mlp` ë˜ëŠ” `ridge`
- `--hidden_layers`: MLP hidden layer í¬ê¸° (MLPë§Œ)
- `--epochs`: í•™ìŠµ ì—í­ ìˆ˜ (MLPë§Œ)
- `--save_model`: ëª¨ë¸ ì €ì¥ ì—¬ë¶€

**í•™ìŠµ ê²°ê³¼**:
- ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: `./outputs/meta_features/meta_classifier_mlp.pth` (ë˜ëŠ” `.joblib`)
- í‰ê°€ ê²°ê³¼: ROC-AUC, Accuracy, F1-Score ì¶œë ¥

### Step 3: Meta-Classifier êµ¬ì¡°

**MLP êµ¬ì¡°**:
```
Input (4 features: Fold Logits)
  â†“
Hidden Layer 1 (64 units, ReLU, Dropout=0.2)
  â†“
Hidden Layer 2 (32 units, ReLU, Dropout=0.2)
  â†“
Output (1 unit, Sigmoid)
```

**Ridge êµ¬ì¡°**:
```
Ridge Regression with L2 Regularization
- Cross-Validationìœ¼ë¡œ ìµœì  alpha ì„ íƒ
- Alpha ë²”ìœ„: 10^-4 ~ 10^2
```

---

## ìµœì¢… ì˜ˆì¸¡ê°’ ê²°ê³¼ í˜•ì‹

### Step 1: Test ë°ì´í„°ì— ëŒ€í•œ Foldë³„ ì˜ˆì¸¡

ê° Fold ëª¨ë¸ë¡œ Test ë°ì´í„° ì˜ˆì¸¡:

```bash
# Foldë³„ ì¶”ë¡  (ê° Foldë§ˆë‹¤ ì‹¤í–‰)
for FOLD in 0 1 2 3; do
    python trainers/fold_trainer.py \
        --fold_idx ${FOLD} \
        --is_submission True \
        --data_dir ./data \
        --model_name HybridAvsH \
        --embedding_model kykim/funnel-kor-base \
        --use_paragraph \
        # ... ê¸°íƒ€ ì¸ì
done
```

### Step 2: Test Logits ì·¨í•©

```python
from utils.logit_collector import collect_test_logits

test_logits = collect_test_logits('./outputs/fold_logits')
print(f"Test logits shape: {test_logits.shape}")  # [N_test, 4]
```

### Step 3: Meta-Classifierë¡œ ìµœì¢… ì˜ˆì¸¡

```bash
python meta/meta_inference.py \
    --meta_model_type mlp \
    --model_path ./outputs/meta_features/meta_classifier_mlp.pth \
    --logit_dir ./outputs/fold_logits \
    --output_dir ./outputs/final_predictions \
    --output_filename submission.csv
```

### ìµœì¢… ê²°ê³¼ íŒŒì¼ í˜•ì‹

**submission.csv**:
```csv
id,generated,probability
0,0,0.234
1,1,0.876
2,0,0.445
3,1,0.912
...
```

**ì»¬ëŸ¼ ì„¤ëª…**:
- `id`: ìƒ˜í”Œ ì¸ë±ìŠ¤ (0ë¶€í„° ì‹œì‘)
- `generated`: ì˜ˆì¸¡ ë ˆì´ë¸” (0: Human, 1: AI)
- `probability`: AIì¼ í™•ë¥  (0.0 ~ 1.0)

---

## ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

### ì™„ì „ ìë™í™” ìŠ¤í¬ë¦½íŠ¸

**run_pipeline.py** (ì˜ˆì‹œ):
```python
#!/usr/bin/env python
"""
v1.3 ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
"""

import os
from trainers.fold_trainer import train_all_folds
from utils.arguments import get_arguments
from utils.logit_collector import LogitCollector
from meta.meta_train import main as train_meta
from meta.meta_inference import main as infer_meta

def main():
    print("="*60)
    print("v1.3 Pipeline: Training and Inference")
    print("="*60)
    
    # Step 1: Foldë³„ í•™ìŠµ
    print("\n[Step 1/4] Training 4 Folds...")
    args = get_arguments()
    args.model_name = 'HybridAvsH'
    args.use_infonce_loss = True
    args.lambda_cl = 0.1
    args.save_fold_logits = True
    args.k_fold = 4
    args.is_kfold = True
    args.use_paragraph = True
    
    train_all_folds(args)
    
    # Step 2: Meta-Features ìƒì„±
    print("\n[Step 2/4] Creating Meta-Features...")
    collector = LogitCollector('./outputs/fold_logits')
    collector.save_meta_features('./outputs/meta_features', 'meta_train.csv')
    
    # Step 3: Meta-Classifier í•™ìŠµ
    print("\n[Step 3/4] Training Meta-Classifier...")
    import sys
    sys.argv = [
        'meta_train.py',
        '--meta_model_type', 'mlp',
        '--hidden_layers', '64', '32',
        '--epochs', '100',
        '--save_model'
    ]
    train_meta()
    
    # Step 4: ìµœì¢… ì˜ˆì¸¡
    print("\n[Step 4/4] Generating Final Predictions...")
    sys.argv = [
        'meta_inference.py',
        '--meta_model_type', 'mlp',
        '--output_filename', 'submission.csv'
    ]
    infer_meta()
    
    print("\n" + "="*60)
    print("âœ… Pipeline Complete!")
    print("Final predictions saved to: ./outputs/final_predictions/submission.csv")
    print("="*60)

if __name__ == "__main__":
    main()
```

### ì‹¤í–‰ ìˆœì„œ ìš”ì•½

```bash
# 1. í™˜ê²½ ì„¤ì •
pip install -r requirements.txt

# 2. ë°ì´í„° ì¤€ë¹„
# data/train.csv, data/test.csv ì¤€ë¹„

# 3. Foldë³„ í•™ìŠµ (4ê°œ Fold)
python trainers/fold_trainer.py --fold_idx 0 --save_fold_logits True ...
python trainers/fold_trainer.py --fold_idx 1 --save_fold_logits True ...
python trainers/fold_trainer.py --fold_idx 2 --save_fold_logits True ...
python trainers/fold_trainer.py --fold_idx 3 --save_fold_logits True ...

# 4. Meta-Features ìƒì„±
python -c "from utils.logit_collector import LogitCollector; LogitCollector('./outputs/fold_logits').save_meta_features()"

# 5. Meta-Classifier í•™ìŠµ
python meta/meta_train.py --meta_model_type mlp --save_model

# 6. ìµœì¢… ì˜ˆì¸¡
python meta/meta_inference.py --meta_model_type mlp
```

---

## ì˜ˆìƒ ì†Œìš” ì‹œê°„

| ë‹¨ê³„ | ì‘ì—… | ì˜ˆìƒ ì‹œê°„ (ë‹¨ì¼ GPU) | ì˜ˆìƒ ì‹œê°„ (4ê°œ GPU ë³‘ë ¬) |
|------|------|---------------------|------------------------|
| Step 1 | Foldë³„ í•™ìŠµ (4ê°œ) | 20-28ì‹œê°„ | 8-10ì‹œê°„ |
| Step 2 | Meta-Features ìƒì„± | 10ë¶„ | 10ë¶„ |
| Step 3 | Meta-Classifier í•™ìŠµ | 30ë¶„-1ì‹œê°„ | 30ë¶„-1ì‹œê°„ |
| Step 4 | ìµœì¢… ì˜ˆì¸¡ | 10ë¶„ | 10ë¶„ |
| **ì´ê³„** | | **21-30ì‹œê°„** | **9-12ì‹œê°„** |

---

## ì£¼ì˜ì‚¬í•­

1. **ë©”ëª¨ë¦¬**: ê° Fold í•™ìŠµ ì‹œ ì•½ 4-8GB GPU ë©”ëª¨ë¦¬ í•„ìš”
2. **ì €ì¥ê³µê°„**: Logits ì €ì¥ ì‹œ ì•½ 500MB-1GB í•„ìš”
3. **ë°ì´í„° ì¼ê´€ì„±**: ëª¨ë“  Foldì—ì„œ ë™ì¼í•œ ë°ì´í„° ë¶„í•  ì‚¬ìš© (K-Fold splitì€ ìë™ ì €ì¥ë¨)
4. **ëª¨ë¸ ì €ì¥**: ê° Foldì˜ best modelì€ `outputs/fold_{idx}/best_model/`ì— ì €ì¥

---

## íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë¬¸ì œ: Logitsê°€ ì €ì¥ë˜ì§€ ì•ŠìŒ
- í•´ê²°: `--save_fold_logits True` ì¸ì í™•ì¸
- í•´ê²°: `outputs/fold_logits/` ë””ë ‰í† ë¦¬ ê¶Œí•œ í™•ì¸

### ë¬¸ì œ: Meta-Features ìƒì„± ì‹¤íŒ¨
- í•´ê²°: 4ê°œ Fold ëª¨ë‘ í•™ìŠµ ì™„ë£Œ í™•ì¸
- í•´ê²°: `fold_logits/oof/fold0_logits.npy` íŒŒì¼ ì¡´ì¬ í™•ì¸

### ë¬¸ì œ: Meta-Classifier í•™ìŠµ ì‹¤íŒ¨
- í•´ê²°: Meta-Features CSV íŒŒì¼ í™•ì¸
- í•´ê²°: Labelsì™€ Logits ê°œìˆ˜ ì¼ì¹˜ í™•ì¸

---

## ì°¸ê³  ìë£Œ

- **êµ¬í˜„ ê°€ì´ë“œ**: `v1.3_implementation_guide.md`
- **ëª¨ë¸ ìš”ì•½**: `v1.3_models_summary.md`
- **íŒŒì¼ êµ¬ì¡°**: `v1.3_file_structure.md`

