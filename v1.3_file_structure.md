# v1.3 íŒŒì¼ êµ¬ì¡° ë° ì¬ì‚¬ìš© ê°€ì´ë“œ

## ğŸ“‚ íŒŒì¼ ë§¤í•‘ í…Œì´ë¸”

### SKKUAI í”„ë¡œì íŠ¸ â†’ v1.3 ì¬ì‚¬ìš©

| ì›ë³¸ íŒŒì¼ | Mut4 ê²½ë¡œ | ìƒíƒœ | ë³€ê²½ í•„ìš” ì—¬ë¶€ |
|-----------|-----------|------|----------------|
| `models/AvsHModel.py` | `models/AvsHModel.py` | âœ… ì¬ì‚¬ìš© | âŒ ì—†ìŒ |
| `datasets_ours/text_dataset.py` | `datasets/text_dataset.py` | âœ… ì¬ì‚¬ìš© | âŒ ì—†ìŒ |
| `datasets_ours/text_collator.py` | `datasets/text_collator.py` | âœ… ì¬ì‚¬ìš© | âŒ ì—†ìŒ |
| `datasets_ours/get_dataset.py` | `datasets/get_dataset.py` | âœ… ì™„ë£Œ | âœ… Import ê²½ë¡œ ìˆ˜ì • ì™„ë£Œ |
| `text_trainer.py` | `trainers/hybrid_trainer.py` | âœ… ì™„ë£Œ | âœ… InfoNCE Loss ì¶”ê°€ ì™„ë£Œ |
| `utils/compute_metrics.py` | `utils/compute_metrics.py` | âœ… ì™„ë£Œ | âœ… Logit ì €ì¥ ë¡œì§ ì¶”ê°€ ì™„ë£Œ |
| `arguments.py` | `utils/arguments.py` | âœ… ì™„ë£Œ | âœ… AIGT ëª¨ë¸ ì¸ì ì¶”ê°€ ì™„ë£Œ |
| `additional_loss.py` | `utils/losses.py` | âœ… ì™„ë£Œ | âœ… InfoNCE Loss í†µí•© ì™„ë£Œ |

### AIGT í”„ë¡œì íŠ¸ â†’ v1.3 ì¬ì‚¬ìš©

| ì›ë³¸ íŒŒì¼ | Mut4 ê²½ë¡œ | ìƒíƒœ | ë³€ê²½ í•„ìš” ì—¬ë¶€ |
|-----------|-----------|------|----------------|
| `module/gemma3_seqcls_infonce.py` | `models/gemma3_seqcls_infonce.py` | âœ… ì¬ì‚¬ìš© | âŒ ì—†ìŒ |
| `module/qwen3_seqcls_infonce.py` | `models/qwen3_seqcls_infonce.py` | âœ… ì¬ì‚¬ìš© | âŒ ì—†ìŒ |

### ìƒˆë¡œ ìƒì„±í•œ íŒŒì¼ (êµ¬í˜„ ì™„ë£Œ)

| íŒŒì¼ ê²½ë¡œ | ìš©ë„ | ìƒíƒœ |
|-----------|------|------|
| `models/hybrid_model.py` | AvsH + InfoNCE í†µí•© ëª¨ë¸ | âœ… ì™„ë£Œ |
| `trainers/hybrid_trainer.py` | í†µí•© Trainer (BCE + BPR + InfoNCE) | âœ… ì™„ë£Œ |
| `trainers/fold_trainer.py` | Foldë³„ í•™ìŠµ ê´€ë¦¬ | âœ… ì™„ë£Œ |
| `datasets/meta_dataset.py` | Meta-Features ìƒì„± | âœ… ì™„ë£Œ |
| `meta/meta_classifier.py` | MLP/Ridge Meta-Classifier | âœ… ì™„ë£Œ |
| `meta/meta_train.py` | Meta-Classifier í•™ìŠµ | âœ… ì™„ë£Œ |
| `meta/meta_inference.py` | ìµœì¢… ì˜ˆì¸¡ | âœ… ì™„ë£Œ |
| `utils/logit_collector.py` | Fold Logits ìˆ˜ì§‘ | âœ… ì™„ë£Œ |
| `utils/losses.py` | BPR + InfoNCE Loss í†µí•© | âœ… ì™„ë£Œ |

---

## ğŸ”„ ì½”ë“œ ì¬ì‚¬ìš© ì „ëµ

### ì „ëµ 1: ì§ì ‘ ë³µì‚¬ í›„ ìˆ˜ì • (ê¶Œì¥)

**ì¥ì **: 
- ê¸°ì¡´ ì½”ë“œ ì™„ì „íˆ ë³´ì¡´
- ë‹¨ê³„ë³„ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥

**ë‹¨ê³„**:
```bash
# 1. SKKUAI íŒŒì¼ ë³µì‚¬
cp -r 2025_SW_Centered_University_Digital_Competition_SKKUAI/models v1.3/
cp -r 2025_SW_Centered_University_Digital_Competition_SKKUAI/datasets_ours v1.3/datasets
cp -r 2025_SW_Centered_University_Digital_Competition_SKKUAI/utils v1.3/

# 2. AIGT íŒŒì¼ ë³µì‚¬
cp 2025-digital-aigt-detection/module/gemma3_seqcls_infonce.py v1.3/models/
cp 2025-digital-aigt-detection/module/qwen3_seqcls_infonce.py v1.3/models/

# 3. ìƒˆ íŒŒì¼ ìƒì„± (ìœ„ í…Œì´ë¸” ì°¸ì¡°)
```

### ì „ëµ 2: ì‹¬ë³¼ë¦­ ë§í¬ (ê°œë°œ ì¤‘)

**ì¥ì **: 
- ì›ë³¸ê³¼ ë™ê¸°í™” ìœ ì§€
- ë””ìŠ¤í¬ ê³µê°„ ì ˆì•½

**ë‹¨ê³„**:
```bash
# Linux/Mac
ln -s ../../2025_SW_Centered_University_Digital_Competition_SKKUAI/models v1.3/models_base

# Windows (mklink)
mklink /D v1.3\models_base ..\..\2025_SW_Centered_University_Digital_Competition_SKKUAI\models
```

---

## ğŸ“ ì£¼ìš” ìˆ˜ì • í¬ì¸íŠ¸

### 1. `models/get_model.py` ìˆ˜ì •

**ë³€ê²½ ì „**:
```python
def get_model(args):
    if args.model_name == 'AvsHModel':
        from models.AvsHModel import AvsHModel
        model = AvsHModel(args)
    else:
        model = AutoModelForSequenceClassification.from_pretrained(...)
    return model, tokenizer
```

**ë³€ê²½ í›„**:
```python
def get_model(args):
    if args.model_name == 'AvsHModel':
        from models.avsh_model import AvsHModel
        model = AvsHModel(args)
    elif args.model_name == 'Gemma3InfoNCE':
        from models.gemma3_infonce import Gemma3ForSequenceClassification
        model = Gemma3ForSequenceClassification.from_pretrained(...)
    elif args.model_name == 'Qwen3InfoNCE':
        from models.qwen3_infonce import Qwen3ForSequenceClassificationCL
        model = Qwen3ForSequenceClassificationCL.from_pretrained(...)
    elif args.model_name == 'HybridAvsH':
        from models.hybrid_model import HybridAvsHModel  # ğŸ†•
        model = HybridAvsHModel(args)
    else:
        model = AutoModelForSequenceClassification.from_pretrained(...)
    return model, tokenizer
```

### 2. `trainers/hybrid_trainer.py` ìˆ˜ì •

**ë³€ê²½ ì „** (text_trainer.py):
```python
class TextTrainer(Trainer):
    def compute_loss(self, model, inputs, return_outputs=False):
        total_logits, paragraph_logits = model(**inputs)
        total_loss = BCEWithLogitsLoss()(total_logits, labels)
        return total_loss
```

**ë³€ê²½ í›„**:
```python
class HybridTrainer(TextTrainer):
    def compute_loss(self, model, inputs, return_outputs=False):
        contrastive_labels = inputs.pop("contrastive_labels", None)
        
        if hasattr(model, 'forward') and 'contrastive_labels' in inspect.signature(model.forward).parameters:
            # Hybrid ëª¨ë¸: InfoNCE Loss ì§€ì›
            total_logits, paragraph_logits, cl_loss = model(
                **inputs,
                contrastive_labels=contrastive_labels,
                lambda_cl=self.args_original.lambda_cl
            )
            total_loss = BCEWithLogitsLoss()(total_logits, labels)
            if cl_loss is not None:
                total_loss += self.args_original.lambda_cl * cl_loss
        else:
            # ê¸°ì¡´ ëª¨ë¸: InfoNCE Loss ì—†ìŒ
            total_logits, paragraph_logits = model(**inputs)
            total_loss = BCEWithLogitsLoss()(total_logits, labels)
        
        return total_loss
```

### 3. `utils/compute_metrics.py` ìˆ˜ì •

**ë³€ê²½ ì „**:
```python
def compute_metrics(eval_preds):
    logits = eval_preds.predictions
    labels = eval_preds.label_ids
    # ... ë©”íŠ¸ë¦­ ê³„ì‚°
    return metric
```

**ë³€ê²½ í›„**:
```python
def compute_metrics(eval_preds):
    logits = eval_preds.predictions
    labels = eval_preds.label_ids
    
    # Foldë³„ Logit ì €ì¥ (v1.3 ì¶”ê°€)
    if hasattr(args, 'save_fold_logits') and args.save_fold_logits:
        fold_idx = args.fold_idx
        logit_dir = f"./outputs/fold_logits"
        os.makedirs(logit_dir, exist_ok=True)
        
        if fold_idx == 0:
            # OOF Logits (Fold 0)
            np.save(f"{logit_dir}/oof/fold0_logits.npy", logits)
            np.save(f"{logit_dir}/oof/fold0_labels.npy", labels)
        else:
            # Test Logits (Fold 1,2,3)
            np.save(f"{logit_dir}/test/fold{fold_idx}_logits.npy", logits)
    
    # ... ê¸°ì¡´ ë©”íŠ¸ë¦­ ê³„ì‚°
    return metric
```

### 4. `utils/arguments.py` ìˆ˜ì •

**ì¶”ê°€í•  ì¸ì**:
```python
# AIGT ëª¨ë¸ ê´€ë ¨
parser.add_argument('--use_infonce_loss', type=bool, default=False, 
                    help='Use InfoNCE Loss for contrastive learning')
parser.add_argument('--lambda_cl', type=float, default=0.1, 
                    help='Weight for InfoNCE Loss')
parser.add_argument('--temperature', type=float, default=0.07, 
                    help='Temperature for InfoNCE Loss')

# Meta-Learning ê´€ë ¨
parser.add_argument('--save_fold_logits', type=bool, default=False, 
                    help='Save fold logits for meta-learning')
parser.add_argument('--meta_model_type', type=str, default='mlp', 
                    choices=['mlp', 'ridge'], help='Meta-classifier type')
```

---

## ğŸ¯ êµ¬í˜„ ìˆœì„œ (ìš°ì„ ìˆœìœ„)

### Phase 1: ê¸°ì´ˆ êµ¬ì¡° (1-2ì¼)
1. âœ… ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
2. âœ… ê¸°ì¡´ íŒŒì¼ ë³µì‚¬/ë§í¬
3. âœ… Import ê²½ë¡œ ìˆ˜ì •
4. âœ… ê¸°ë³¸ ì‹¤í–‰ í…ŒìŠ¤íŠ¸

### Phase 2: ëª¨ë¸ í†µí•© (2-3ì¼)
1. âœ… HybridAvsHModel êµ¬í˜„
2. âœ… HybridTrainer êµ¬í˜„
3. âœ… Loss í†µí•© (BCE + BPR + InfoNCE)
4. âœ… ë‹¨ì¼ ëª¨ë¸ í•™ìŠµ í…ŒìŠ¤íŠ¸

### Phase 3: Fold íŒŒì´í”„ë¼ì¸ (2-3ì¼)
1. âœ… FoldTrainer êµ¬í˜„
2. âœ… Logit ì €ì¥ ë¡œì§
3. âœ… 4-Fold í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
4. âœ… ë³‘ë ¬ í•™ìŠµ í…ŒìŠ¤íŠ¸

### Phase 4: Meta-Learning (1-2ì¼)
1. âœ… Meta-Features ìƒì„±
2. âœ… Meta-Classifier êµ¬í˜„
3. âœ… Meta í•™ìŠµ/ì¶”ë¡  íŒŒì´í”„ë¼ì¸
4. âœ… End-to-End í…ŒìŠ¤íŠ¸

---

## ğŸ” ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ëª¨ë¸ í†µí•© ê²€ì¦
- [ ] AvsHModel ì •ìƒ ì‘ë™ í™•ì¸
- [ ] InfoNCE Loss ê³„ì‚° í™•ì¸
- [ ] Hybrid ëª¨ë¸ í•™ìŠµ í™•ì¸
- [ ] Loss ê°’ ìˆ˜ë ´ í™•ì¸

### Fold íŒŒì´í”„ë¼ì¸ ê²€ì¦
- [ ] 4-Fold ë°ì´í„° ë¶„í•  í™•ì¸
- [ ] Foldë³„ ë…ë¦½ í•™ìŠµ í™•ì¸
- [ ] OOF Logits ì €ì¥ í™•ì¸
- [ ] Test Logits ì €ì¥ í™•ì¸

### Meta-Learning ê²€ì¦
- [ ] Meta-Features Shape í™•ì¸ ([Num_Samples] Ã— 4)
- [ ] Meta-Classifier í•™ìŠµ í™•ì¸
- [ ] ìµœì¢… ì˜ˆì¸¡ ìƒì„± í™•ì¸
- [ ] ì„±ëŠ¥ í–¥ìƒ í™•ì¸

---

## ğŸ“Š ì˜ˆìƒ íŒŒì¼ í¬ê¸°

| íŒŒì¼ ìœ í˜• | ê°œìˆ˜ | ì˜ˆìƒ í¬ê¸° |
|-----------|------|-----------|
| ëª¨ë¸ íŒŒì¼ (.py) | ~10ê°œ | ~50KB |
| ë°ì´í„° ì²˜ë¦¬ (.py) | ~5ê°œ | ~30KB |
| í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ (.py) | ~5ê°œ | ~40KB |
| Meta-Learning (.py) | ~3ê°œ | ~20KB |
| ì„¤ì • íŒŒì¼ (.yaml) | ~2ê°œ | ~5KB |
| Shell ìŠ¤í¬ë¦½íŠ¸ (.sh) | ~5ê°œ | ~10KB |
| **ì´ê³„** | **~30ê°œ** | **~155KB** |

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ

### 1. ë””ë ‰í† ë¦¬ ìƒì„±
```bash
mkdir -p v1.3/{models,datasets,trainers,meta,scripts,utils,configs,outputs}
mkdir -p v1.3/outputs/{fold_logits/{oof,test},meta_features,final_predictions}
```

### 2. íŒŒì¼ ë³µì‚¬
```bash
# SKKUAI
cp 2025_SW_Centered_University_Digital_Competition_SKKUAI/models/AvsHModel.py v1.3/models/avsh_model.py
cp 2025_SW_Centered_University_Digital_Competition_SKKUAI/datasets_ours/*.py v1.3/datasets/
cp 2025_SW_Centered_University_Digital_Competition_SKKUAI/utils/*.py v1.3/utils/

# AIGT
cp 2025-digital-aigt-detection/module/gemma3_seqcls_infonce.py v1.3/models/
cp 2025-digital-aigt-detection/module/qwen3_seqcls_infonce.py v1.3/models/
```

### 3. ìƒˆ íŒŒì¼ ìƒì„± (ìœ„ ê°€ì´ë“œ ì°¸ì¡°)

### 4. ì‹¤í–‰ í…ŒìŠ¤íŠ¸
```bash
cd v1.3
python train_fold.py --fold_idx 0 --test_mode
```

---

## ğŸ“š ì°¸ê³  ë¬¸ì„œ

- `v1.3_implementation_guide.md`: ì „ì²´ êµ¬í˜„ ê°€ì´ë“œ
- `INTEGRATION_ARCHITECTURE.md`: ì•„í‚¤í…ì²˜ í†µí•© ë¬¸ì„œ
- `final_architecture.md`: ìµœì¢… ì•„í‚¤í…ì²˜ ì„¤ê³„

